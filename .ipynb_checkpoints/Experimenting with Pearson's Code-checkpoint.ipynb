{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import model_fit_history as mfh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155520\n",
      "155520\n"
     ]
    }
   ],
   "source": [
    "X_train,y_train,pvals,keys,time = mfh.load_data('transit_data_train.pkl',whiten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.5 2.5 3.5 4.5]\n",
      "1.0\n",
      "rp 0.01414213562373095\n",
      "per 2.0\n",
      "inc 86.0\n",
      "sig_tol 1.5\n",
      "phi 0.0\n",
      "A 0.00025\n",
      "w 0.5\n",
      "PA -1.0\n",
      "Pw 1.0\n",
      "\n",
      "\n",
      "1.0\n",
      "rp 0.1\n",
      "per 4.0\n",
      "inc 90.0\n",
      "sig_tol 1.5\n",
      "phi 3.141592653589793\n",
      "A 0.002\n",
      "w 1.0\n",
      "PA 100.0\n",
      "Pw 100.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(np.unique(pvals[:,3]))\n",
    "ind = np.argwhere(pvals[:,3] == 1.5)\n",
    "\n",
    "n = 10\n",
    "plt.scatter(time, X_train[n,:])\n",
    "print(y_train[n])\n",
    "for i in range(len(keys)):\n",
    "    print(keys[i], pvals[n, i])\n",
    "    \n",
    "print('\\n')\n",
    "\n",
    "n = ind[-1][0]\n",
    "print(y_train[n])\n",
    "plt.scatter(time, X_train[n,:])\n",
    "for i in range(len(keys)):\n",
    "    print(keys[i], pvals[n, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(311040, 180, 1)\n"
     ]
    }
   ],
   "source": [
    "Xc_train = X_train.reshape((X_train.shape[0],X_train.shape[1],1))\n",
    "print(Xc_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Sequential in module keras.models object:\n",
      "\n",
      "class Sequential(keras.engine.training.Model)\n",
      " |  Linear stack of layers.\n",
      " |  \n",
      " |  # Arguments\n",
      " |      layers: list of layers to add to the model.\n",
      " |  \n",
      " |  # Note\n",
      " |      The first layer passed to a Sequential model\n",
      " |      should have a defined input shape. What that\n",
      " |      means is that it should have received an `input_shape`\n",
      " |      or `batch_input_shape` argument,\n",
      " |      or for some type of layers (recurrent, Dense...)\n",
      " |      an `input_dim` argument.\n",
      " |  \n",
      " |  # Example\n",
      " |  \n",
      " |      ```python\n",
      " |          model = Sequential()\n",
      " |          # first layer must have a defined input shape\n",
      " |          model.add(Dense(32, input_dim=500))\n",
      " |          # afterwards, Keras does automatic shape inference\n",
      " |          model.add(Dense(32))\n",
      " |  \n",
      " |          # also possible (equivalent to the above):\n",
      " |          model = Sequential()\n",
      " |          model.add(Dense(32, input_shape=(500,)))\n",
      " |          model.add(Dense(32))\n",
      " |  \n",
      " |          # also possible (equivalent to the above):\n",
      " |          model = Sequential()\n",
      " |          # here the batch dimension is None,\n",
      " |          # which means any batch size will be accepted by the model.\n",
      " |          model.add(Dense(32, batch_input_shape=(None, 500)))\n",
      " |          model.add(Dense(32))\n",
      " |      ```\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Sequential\n",
      " |      keras.engine.training.Model\n",
      " |      keras.engine.topology.Container\n",
      " |      keras.engine.topology.Layer\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, layers=None, name=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  add(self, layer)\n",
      " |      Adds a layer instance on top of the layer stack.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          layer: layer instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          TypeError: If `layer` is not a layer instance.\n",
      " |          ValueError: In case the `layer` argument does not\n",
      " |              know its input shape.\n",
      " |          ValueError: In case the `layer` argument has\n",
      " |              multiple output tensors, or is already connected\n",
      " |              somewhere else (forbidden in `Sequential` models).\n",
      " |  \n",
      " |  build(self, input_shape=None)\n",
      " |      Creates the layer weights.\n",
      " |      \n",
      " |      Must be implemented on all layers that have weights.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Keras tensor (future input to layer)\n",
      " |              or list/tuple of Keras tensors to reference\n",
      " |              for weight shape computations.\n",
      " |  \n",
      " |  call(self, inputs, mask=None)\n",
      " |      Calls the model on new inputs.\n",
      " |      \n",
      " |      In this case `call` just reapplies\n",
      " |      all ops in the graph to the new inputs\n",
      " |      (e.g. build a new computational graph from the provided inputs).\n",
      " |      \n",
      " |      A model is callable on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: A tensor or list of tensors.\n",
      " |          mask: A mask or list of masks. A mask can be\n",
      " |              either a tensor or None (no mask).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor if there is a single output, or\n",
      " |          a list of tensors if there are more than one outputs.\n",
      " |  \n",
      " |  compile(self, optimizer, loss, metrics=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None, **kwargs)\n",
      " |      Configures the model for training.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          optimizer: String (name of optimizer) or optimizer object.\n",
      " |              See [optimizers](/optimizers).\n",
      " |          loss: String (name of objective function) or objective function.\n",
      " |              See [losses](/losses).\n",
      " |              If the model has multiple outputs, you can use a different loss\n",
      " |              on each output by passing a dictionary or a list of losses.\n",
      " |              The loss value that will be minimized by the model\n",
      " |              will then be the sum of all individual losses.\n",
      " |          metrics: List of metrics to be evaluated by the model\n",
      " |              during training and testing.\n",
      " |              Typically you will use `metrics=['accuracy']`.\n",
      " |              To specify different metrics for different outputs of a\n",
      " |              multi-output model, you could also pass a dictionary,\n",
      " |              such as `metrics={'output_a': 'accuracy'}`.\n",
      " |          sample_weight_mode: If you need to do timestep-wise\n",
      " |              sample weighting (2D weights), set this to `\"temporal\"`.\n",
      " |              `None` defaults to sample-wise weights (1D).\n",
      " |              If the model has multiple outputs, you can use a different\n",
      " |              `sample_weight_mode` on each output by passing a\n",
      " |              dictionary or a list of modes.\n",
      " |          weighted_metrics: List of metrics to be evaluated and weighted\n",
      " |              by sample_weight or class_weight during training and testing.\n",
      " |          target_tensors: By default, Keras will create a placeholder for the\n",
      " |              model's target, which will be fed with the target data during\n",
      " |              training. If instead you would like to use your own\n",
      " |              target tensor (in turn, Keras will not expect external\n",
      " |              Numpy data for these targets at training time), you\n",
      " |              can specify them via the `target_tensors` argument.\n",
      " |              It should be a single tensor\n",
      " |              (for a single-output `Sequential` model).\n",
      " |          **kwargs: When using the Theano/CNTK backends, these arguments\n",
      " |              are passed into `K.function`.\n",
      " |              When using the TensorFlow backend,\n",
      " |              these arguments are passed into `tf.Session.run`.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of invalid arguments for\n",
      " |              `optimizer`, `loss`, `metrics` or `sample_weight_mode`.\n",
      " |      \n",
      " |      # Example\n",
      " |          ```python\n",
      " |              model = Sequential()\n",
      " |              model.add(Dense(32, input_shape=(500,)))\n",
      " |              model.add(Dense(10, activation='softmax'))\n",
      " |              model.compile(optimizer='rmsprop',\n",
      " |                            loss='categorical_crossentropy',\n",
      " |                            metrics=['accuracy'])\n",
      " |          ```\n",
      " |  \n",
      " |  evaluate(self, x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)\n",
      " |      Computes the loss on some input data, batch by batch.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: labels, as a Numpy array.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |          sample_weight: sample weights, as a Numpy array.\n",
      " |          steps: Integer or `None`.\n",
      " |              Total number of steps (batches of samples)\n",
      " |              before declaring the evaluation round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has no metrics)\n",
      " |          or list of scalars (if the model computes other metrics).\n",
      " |          The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the model was never compiled.\n",
      " |  \n",
      " |  evaluate_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
      " |      Evaluates the model on a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data\n",
      " |      as accepted by `test_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: Generator yielding tuples (inputs, targets)\n",
      " |              or (inputs, targets, sample_weights)\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: maximum number of processes to spin up\n",
      " |          use_multiprocessing: if True, use process based threading.\n",
      " |              Note that because this implementation\n",
      " |              relies on multiprocessing, you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has no metrics)\n",
      " |          or list of scalars (if the model computes other metrics).\n",
      " |          The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the model was never compiled.\n",
      " |  \n",
      " |  fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, **kwargs)\n",
      " |      Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: Numpy array of training data.\n",
      " |              If the input layer in the model is named, you can also pass a\n",
      " |              dictionary mapping the input name to a Numpy array.\n",
      " |              `x` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          y: Numpy array of target (label) data.\n",
      " |              If the output layer in the model is named, you can also pass a\n",
      " |              dictionary mapping the output name to a Numpy array.\n",
      " |              `y` can be `None` (default) if feeding from\n",
      " |              framework-native tensors (e.g. TensorFlow data tensors).\n",
      " |          batch_size: Integer or `None`.\n",
      " |              Number of samples per gradient update.\n",
      " |              If unspecified, it will default to 32.\n",
      " |          epochs: Integer. Number of epochs to train the model.\n",
      " |              An epoch is an iteration over the entire `x` and `y`\n",
      " |              data provided.\n",
      " |              Note that in conjunction with `initial_epoch`,\n",
      " |              `epochs` is to be understood as \"final epoch\".\n",
      " |              The model is not trained for a number of iterations\n",
      " |              given by `epochs`, but merely until the epoch\n",
      " |              of index `epochs` is reached.\n",
      " |          verbose: 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_split: Float between 0 and 1.\n",
      " |              Fraction of the training data to be used as validation data.\n",
      " |              The model will set apart this fraction of the training data,\n",
      " |              will not train on it, and will evaluate\n",
      " |              the loss and any model metrics\n",
      " |              on this data at the end of each epoch.\n",
      " |              The validation data is selected from the last samples\n",
      " |              in the `x` and `y` data provided, before shuffling.\n",
      " |          validation_data: tuple `(x_val, y_val)` or tuple\n",
      " |              `(x_val, y_val, val_sample_weights)` on which to evaluate\n",
      " |              the loss and any model metrics at the end of each epoch.\n",
      " |              The model will not be trained on this data.\n",
      " |              This will override `validation_split`.\n",
      " |          shuffle: Boolean (whether to shuffle the training data\n",
      " |              before each epoch) or str (for 'batch').\n",
      " |              'batch' is a special option for dealing with the\n",
      " |              limitations of HDF5 data; it shuffles in batch-sized chunks.\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only).\n",
      " |              This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from\n",
      " |              an under-represented class.\n",
      " |          sample_weight: Optional Numpy array of weights for\n",
      " |              the training samples, used for weighting the loss function\n",
      " |              (during training only). You can either pass a flat (1D)\n",
      " |              Numpy array with the same length as the input samples\n",
      " |              (1:1 mapping between weights and samples),\n",
      " |              or in the case of temporal data,\n",
      " |              you can pass a 2D array with shape\n",
      " |              `(samples, sequence_length)`,\n",
      " |              to apply a different weight to every timestep of every sample.\n",
      " |              In this case you should make sure to specify\n",
      " |              `sample_weight_mode=\"temporal\"` in `compile()`.\n",
      " |          initial_epoch: Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |          steps_per_epoch: Total number of steps (batches of samples)\n",
      " |              before declaring one epoch finished and starting the\n",
      " |              next epoch. When training with input tensors such as\n",
      " |              TensorFlow data tensors, the default `None` is equal to\n",
      " |              the number of samples in your dataset divided by\n",
      " |              the batch size, or 1 if that cannot be determined.\n",
      " |          validation_steps: Only relevant if `steps_per_epoch`\n",
      " |              is specified. Total number of steps (batches of samples)\n",
      " |              to validate before stopping.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object. Its `History.history` attribute is\n",
      " |          a record of training loss values and metrics values\n",
      " |          at successive epochs, as well as validation loss values\n",
      " |          and validation metrics values (if applicable).\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: If the model was never compiled.\n",
      " |          ValueError: In case of mismatch between the provided input data\n",
      " |              and what the model expects.\n",
      " |  \n",
      " |  fit_generator(self, generator, steps_per_epoch=None, epochs=1, verbose=1, callbacks=None, validation_data=None, validation_steps=None, class_weight=None, max_queue_size=10, workers=1, use_multiprocessing=False, shuffle=True, initial_epoch=0)\n",
      " |      Fits the model on data generated batch-by-batch by a Python generator.\n",
      " |      \n",
      " |      The generator is run in parallel to the model, for efficiency.\n",
      " |      For instance, this allows you to do real-time data augmentation\n",
      " |      on images on CPU in parallel to training your model on GPU.\n",
      " |      \n",
      " |      The use of `keras.utils.Sequence` guarantees the ordering\n",
      " |      and guarantees the single use of every input per epoch when\n",
      " |      using `use_multiprocessing=True`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: A generator or an instance of `Sequence`\n",
      " |              (`keras.utils.Sequence`) object in order to avoid duplicate data\n",
      " |                  when using multiprocessing.\n",
      " |              The output of the generator must be either\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |              This tuple (a single output of the generator) makes a single\n",
      " |              batch. Therefore, all arrays in this tuple must have the same\n",
      " |              length (equal to the size of this batch). Different batches may\n",
      " |              have different sizes. For example, the last batch of the epoch\n",
      " |              is commonly smaller than the others, if the size of the dataset\n",
      " |              is not divisible by the batch size.\n",
      " |              The generator is expected to loop over its data\n",
      " |              indefinitely. An epoch finishes when `steps_per_epoch`\n",
      " |              batches have been seen by the model.\n",
      " |          steps_per_epoch: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before declaring one epoch\n",
      " |              finished and starting the next epoch. It should typically\n",
      " |              be equal to the number of samples of your dataset\n",
      " |              divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          epochs: Integer, total number of iterations on the data.\n",
      " |              Note that in conjunction with initial_epoch, the parameter\n",
      " |              epochs is to be understood as \"final epoch\". The model is\n",
      " |              not trained for n steps given by epochs, but until the\n",
      " |              epoch epochs is reached.\n",
      " |          verbose: Integer. 0, 1, or 2. Verbosity mode.\n",
      " |              0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      " |          callbacks: List of `keras.callbacks.Callback` instances.\n",
      " |              List of callbacks to apply during training.\n",
      " |              See [callbacks](/callbacks).\n",
      " |          validation_data: This can be either\n",
      " |              - a generator for the validation data\n",
      " |              - a tuple `(inputs, targets)`\n",
      " |              - a tuple `(inputs, targets, sample_weights)`.\n",
      " |          validation_steps: Only relevant if `validation_data`\n",
      " |              is a generator. Total number of steps (batches of samples)\n",
      " |              to yield from `validation_data` generator before stopping\n",
      " |              at the end of every epoch. It should typically\n",
      " |              be equal to the number of samples of your\n",
      " |              validation dataset divided by the batch size.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(validation_data)` as a number of steps.\n",
      " |          class_weight: Optional dictionary mapping class indices (integers)\n",
      " |              to a weight (float) value, used for weighting the loss function\n",
      " |              (during training only). This can be useful to tell the model to\n",
      " |              \"pay more attention\" to samples from an under-represented class.\n",
      " |          max_queue_size: Integer. Maximum size for the generator queue.\n",
      " |              If unspecified, `max_queue_size` will default to 10.\n",
      " |          workers: Integer. Maximum number of processes to spin up\n",
      " |              when using process-based threading.\n",
      " |              If unspecified, `workers` will default to 1. If 0, will\n",
      " |              execute the generator on the main thread.\n",
      " |          use_multiprocessing: Boolean.\n",
      " |              If `True`, use process-based threading.\n",
      " |              If unspecified, `use_multiprocessing` will default to `False`.\n",
      " |              Note that because this implementation relies on multiprocessing,\n",
      " |              you should not pass non-picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          shuffle: Boolean (whether to shuffle the order of the batches at\n",
      " |              the beginning of each epoch. Only used with instances\n",
      " |              of `Sequence` (`keras.utils.Sequence`).\n",
      " |              Has no effect when `steps_per_epoch` is not `None`.\n",
      " |          initial_epoch: Integer.\n",
      " |              Epoch at which to start training\n",
      " |              (useful for resuming a previous training run).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A `History` object.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the model was never compiled.\n",
      " |          ValueError: In case the generator yields data in an invalid format.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |          def generate_arrays_from_file(path):\n",
      " |              while True:\n",
      " |                  with open(path) as f:\n",
      " |                      for line in f:\n",
      " |                          # create Numpy arrays of input data\n",
      " |                          # and labels, from each line in the file\n",
      " |                          x, y = process_line(line)\n",
      " |                          yield (x, y)\n",
      " |      \n",
      " |          model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
      " |                              steps_per_epoch=1000, epochs=10)\n",
      " |      ```\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Container` (one layer of abstraction above).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  get_layer(self, name=None, index=None)\n",
      " |      Retrieve a layer that is part of the model.\n",
      " |      \n",
      " |      Returns a layer based on either its name (unique)\n",
      " |      or its index in the graph. Indices are based on\n",
      " |      order of horizontal graph traversal (bottom-up).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: string, name of layer.\n",
      " |          index: integer, index of layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Retrieves the weights of the model.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A flat list of Numpy arrays\n",
      " |          (one array per model weight).\n",
      " |  \n",
      " |  legacy_get_config(self)\n",
      " |      Retrieves the model configuration as a Python list.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of dicts (each dict is a layer config).\n",
      " |  \n",
      " |  load_weights(self, filepath, by_name=False, skip_mismatch=False, reshape=False)\n",
      " |      Loads all layer weights from a HDF5 save file.\n",
      " |      \n",
      " |      If `by_name` is False (default) weights are loaded\n",
      " |      based on the network's topology, meaning the architecture\n",
      " |      should be the same as when the weights were saved.\n",
      " |      Note that layers that don't have weights are not taken\n",
      " |      into account in the topological ordering, so adding or\n",
      " |      removing layers is fine as long as they don't have weights.\n",
      " |      \n",
      " |      If `by_name` is True, weights are loaded into layers\n",
      " |      only if they share the same name. This is useful\n",
      " |      for fine-tuning or transfer-learning models where\n",
      " |      some of the layers have changed.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the weights file to load.\n",
      " |          by_name: Boolean, whether to load weights by name\n",
      " |              or by topological order.\n",
      " |          skip_mismatch: Boolean, whether to skip loading of layers\n",
      " |              where there is a mismatch in the number of weights,\n",
      " |              or a mismatch in the shape of the weight\n",
      " |              (only valid when `by_name`=True).\n",
      " |          reshape: Reshape weights to fit the layer when the correct number\n",
      " |              of weight arrays is present but their shape does not match.\n",
      " |      \n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  pop(self)\n",
      " |      Removes the last layer in the model.\n",
      " |      \n",
      " |      # Raises\n",
      " |          TypeError: if there are no layers in the model.\n",
      " |  \n",
      " |  predict(self, x, batch_size=None, verbose=0, steps=None)\n",
      " |      Generates output predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: the input data, as a Numpy array.\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy array of predictions.\n",
      " |  \n",
      " |  predict_classes(self, x, batch_size=None, verbose=0, steps=None)\n",
      " |      Generate class predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A numpy array of class predictions.\n",
      " |  \n",
      " |  predict_generator(self, generator, steps=None, max_queue_size=10, workers=1, use_multiprocessing=False, verbose=0)\n",
      " |      Generates predictions for the input samples from a data generator.\n",
      " |      \n",
      " |      The generator should return the same kind of data as accepted by\n",
      " |      `predict_on_batch`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          generator: generator yielding batches of input samples.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              to yield from `generator` before stopping.\n",
      " |              Optional for `Sequence`: if unspecified, will use\n",
      " |              the `len(generator)` as a number of steps.\n",
      " |          max_queue_size: maximum size for the generator queue\n",
      " |          workers: maximum number of processes to spin up\n",
      " |          use_multiprocessing: if True, use process based threading.\n",
      " |              Note that because this implementation\n",
      " |              relies on multiprocessing, you should not pass\n",
      " |              non picklable arguments to the generator\n",
      " |              as they can't be passed easily to children processes.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy array of predictions.\n",
      " |  \n",
      " |  predict_on_batch(self, x)\n",
      " |      Returns predictions for a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy array of predictions.\n",
      " |  \n",
      " |  predict_proba(self, x, batch_size=None, verbose=0, steps=None)\n",
      " |      Generates class probability predictions for the input samples.\n",
      " |      \n",
      " |      The input samples are processed batch by batch.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          batch_size: Integer. If unspecified, it will default to 32.\n",
      " |          verbose: verbosity mode, 0 or 1.\n",
      " |          steps: Total number of steps (batches of samples)\n",
      " |              before declaring the prediction round finished.\n",
      " |              Ignored with the default value of `None`.\n",
      " |      \n",
      " |      \n",
      " |      # Returns\n",
      " |          A Numpy array of probability predictions.\n",
      " |  \n",
      " |  save_weights(self, filepath, overwrite=True)\n",
      " |      Dumps all layer weights to a HDF5 file.\n",
      " |      \n",
      " |      The weight file has:\n",
      " |          - `layer_names` (attribute), a list of strings\n",
      " |              (ordered names of model layers).\n",
      " |          - For every layer, a `group` named `layer.name`\n",
      " |              - For every such layer group, a group attribute `weight_names`,\n",
      " |                  a list of strings\n",
      " |                  (ordered names of weights tensor of the layer).\n",
      " |              - For every weight in the layer, a dataset\n",
      " |                  storing the weight value, named after the weight tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ImportError: If h5py is not available.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the model.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          weights: Should be a list\n",
      " |              of Numpy arrays with shapes and types matching\n",
      " |              the output of `model.get_weights()`.\n",
      " |  \n",
      " |  test_on_batch(self, x, y, sample_weight=None)\n",
      " |      Evaluates the model over a single batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          y: labels, as a Numpy array.\n",
      " |          sample_weight: sample weights, as a Numpy array.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar test loss (if the model has no metrics)\n",
      " |          or list of scalars (if the model computes other metrics).\n",
      " |          The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the model was never compiled.\n",
      " |  \n",
      " |  train_on_batch(self, x, y, class_weight=None, sample_weight=None)\n",
      " |      Single gradient update over one batch of samples.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          x: input data, as a Numpy array or list of Numpy arrays\n",
      " |              (if the model has multiple inputs).\n",
      " |          y: labels, as a Numpy array.\n",
      " |          class_weight: dictionary mapping classes to a weight value,\n",
      " |              used for scaling the loss function (during training only).\n",
      " |          sample_weight: sample weights, as a Numpy array.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Scalar training loss (if the model has no metrics)\n",
      " |          or list of scalars (if the model computes other metrics).\n",
      " |          The attribute `model.metrics_names` will give you\n",
      " |          the display labels for the scalar outputs.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the model was never compiled.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_config(config, custom_objects=None) from builtins.type\n",
      " |      Instantiates a Model from its config (output of `get_config()`).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: Model config dictionary.\n",
      " |          custom_objects: Optional dictionary mapping names\n",
      " |              (strings) to custom classes or functions to be\n",
      " |              considered during deserialization.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A model instance.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: In case of improperly formatted config dict.\n",
      " |  \n",
      " |  legacy_from_config(config, layer_cache=None) from builtins.type\n",
      " |      Load a model from a legacy configuration.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          config: dictionary with configuration.\n",
      " |          layer_cache: cache to draw pre-existing layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The loaded Model.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  losses\n",
      " |      Retrieves the model's losses.\n",
      " |      \n",
      " |      Will only include losses that are either\n",
      " |      inconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include losses that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of loss tensors.\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  regularizers\n",
      " |  \n",
      " |  state_updates\n",
      " |      Returns the `updates` from all layers that are stateful.\n",
      " |      \n",
      " |      This is useful for separating training updates and\n",
      " |      state updates, e.g. when we need to update a layer's internal state\n",
      " |      during prediction.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |      Retrieves the model's updates.\n",
      " |      \n",
      " |      Will only include updates that are either\n",
      " |      inconditional, or conditional on inputs to this model\n",
      " |      (e.g. will not include updates that depend on tensors\n",
      " |      that aren't inputs to this model).\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of update ops.\n",
      " |  \n",
      " |  uses_learning_phase\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      # Returns\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      Assumes that the layer will be built\n",
      " |      to match that input shape provided.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  reset_states(self)\n",
      " |  \n",
      " |  run_internal_graph(self, inputs, masks=None)\n",
      " |      Computes output tensors for new inputs.\n",
      " |      \n",
      " |      # Note:\n",
      " |          - Expects `inputs` to be a list (potentially with 1 element).\n",
      " |          - Can be run on non-Keras tensors.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: List of tensors\n",
      " |          masks: List of masks (tensors or None).\n",
      " |      \n",
      " |      # Returns\n",
      " |          Three lists: output_tensors, output_masks, output_shapes\n",
      " |  \n",
      " |  save(self, filepath, overwrite=True, include_optimizer=True)\n",
      " |      Saves the model to a single HDF5 file.\n",
      " |      \n",
      " |      The savefile includes:\n",
      " |          - The model architecture, allowing to re-instantiate the model.\n",
      " |          - The model weights.\n",
      " |          - The state of the optimizer, allowing to resume training\n",
      " |              exactly where you left off.\n",
      " |      \n",
      " |      This allows you to save the entirety of the state of a model\n",
      " |      in a single file.\n",
      " |      \n",
      " |      Saved models can be reinstantiated via `keras.models.load_model`.\n",
      " |      The model returned by `load_model`\n",
      " |      is a compiled model ready to be used (unless the saved model\n",
      " |      was never compiled in the first place).\n",
      " |      \n",
      " |      # Arguments\n",
      " |          filepath: String, path to the file to save the weights to.\n",
      " |          overwrite: Whether to silently overwrite any existing file at the\n",
      " |              target location, or provide the user with a manual prompt.\n",
      " |          include_optimizer: If True, save optimizer's state together.\n",
      " |      \n",
      " |      # Example\n",
      " |      \n",
      " |      ```python\n",
      " |      from keras.models import load_model\n",
      " |      \n",
      " |      model.save('my_model.h5')  # creates a HDF5 file 'my_model.h5'\n",
      " |      del model  # deletes the existing model\n",
      " |      \n",
      " |      # returns a compiled model\n",
      " |      # identical to the previous one\n",
      " |      model = load_model('my_model.h5')\n",
      " |      ```\n",
      " |  \n",
      " |  summary(self, line_length=None, positions=None, print_fn=None)\n",
      " |      Prints a string summary of the network.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          line_length: Total length of printed lines\n",
      " |              (e.g. set this to adapt the display to different\n",
      " |              terminal window sizes).\n",
      " |          positions: Relative or absolute positions of log elements\n",
      " |              in each line. If not provided,\n",
      " |              defaults to `[.33, .55, .67, 1.]`.\n",
      " |          print_fn: Print function to use.\n",
      " |              It will be called on each line of the summary.\n",
      " |              You can set it to a custom function\n",
      " |              in order to capture the string summary.\n",
      " |              It defaults to `print` (prints to stdout).\n",
      " |  \n",
      " |  to_json(self, **kwargs)\n",
      " |      Returns a JSON string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a JSON save file, use\n",
      " |      `keras.models.model_from_json(json_string, custom_objects={})`.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `json.dumps()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A JSON string.\n",
      " |  \n",
      " |  to_yaml(self, **kwargs)\n",
      " |      Returns a yaml string containing the network configuration.\n",
      " |      \n",
      " |      To load a network from a yaml save file, use\n",
      " |      `keras.models.model_from_yaml(yaml_string, custom_objects={})`.\n",
      " |      \n",
      " |      `custom_objects` should be a dictionary mapping\n",
      " |      the names of custom losses / layers / etc to the corresponding\n",
      " |      functions / classes.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          **kwargs: Additional keyword arguments\n",
      " |              to be passed to `yaml.dump()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A YAML string.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Container:\n",
      " |  \n",
      " |  input_spec\n",
      " |      Gets the model's input specs.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A list of `InputSpec` instances (one per input to the model)\n",
      " |              or a single instance if the model has only one input.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, **kwargs)\n",
      " |      Wrapper around self.call(), for handling internal references.\n",
      " |      \n",
      " |      If a Keras tensor is passed:\n",
      " |          - We call self._add_inbound_node().\n",
      " |          - If necessary, we `build` the layer to match\n",
      " |              the _keras_shape of the input(s).\n",
      " |          - We update the _keras_shape of every input tensor with\n",
      " |              its new shape (obtained via self.compute_output_shape).\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |          - We update the _keras_history of the output tensor(s)\n",
      " |              with the current layer.\n",
      " |              This is done as part of _add_inbound_node().\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: Can be a tensor or list/tuple of tensors.\n",
      " |          **kwargs: Additional keyword arguments to be passed to `call()`.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output of the layer's `call` method.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case the layer is missing shape information\n",
      " |              for its `build` call.\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Adds losses to the layer.\n",
      " |      \n",
      " |      The loss may potentially be conditional on some inputs tensors,\n",
      " |      for instance activity losses are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          losses: loss tensor or list of loss tensors\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the losses as conditional on these inputs.\n",
      " |              If None is passed, the loss is assumed unconditional\n",
      " |              (e.g. L2 weight regularization, which only depends\n",
      " |              on the layer's weights variables, not on any inputs tensors).\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Adds updates to the layer.\n",
      " |      \n",
      " |      The updates may potentially be conditional on some inputs tensors,\n",
      " |      for instance batch norm updates are conditional on the layer's inputs.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          updates: update op or list of update ops\n",
      " |              to add to the layer.\n",
      " |          inputs: input tensor or list of inputs tensors to mark\n",
      " |              the updates as conditional on these inputs.\n",
      " |              If None is passed, the updates are assumed unconditional.\n",
      " |  \n",
      " |  add_weight(self, name, shape, dtype=None, initializer=None, regularizer=None, trainable=True, constraint=None)\n",
      " |      Adds a weight variable to the layer.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          name: String, the name for the weight variable.\n",
      " |          shape: The shape tuple of the weight.\n",
      " |          dtype: The dtype of the weight.\n",
      " |          initializer: An Initializer instance (callable).\n",
      " |          regularizer: An optional Regularizer instance.\n",
      " |          trainable: A boolean, whether the weight should\n",
      " |              be trained via backprop or not (assuming\n",
      " |              that the layer itself is also trainable).\n",
      " |          constraint: An optional Constraint instance.\n",
      " |      \n",
      " |      # Returns\n",
      " |          The created weight variable.\n",
      " |  \n",
      " |  assert_input_compatibility(self, inputs)\n",
      " |      Checks compatibility between the layer and provided inputs.\n",
      " |      \n",
      " |      This checks that the tensor(s) `input`\n",
      " |      verify the input assumptions of the layer\n",
      " |      (if any). If not, exceptions are raised.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          inputs: input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          ValueError: in case of mismatch between\n",
      " |              the provided inputs and the expectations of the layer.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Counts the total number of scalars composing the weights.\n",
      " |      \n",
      " |      # Returns\n",
      " |          An integer count.\n",
      " |      \n",
      " |      # Raises\n",
      " |          RuntimeError: if the layer isn't yet built\n",
      " |              (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      # Arguments\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      # Returns\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from keras.engine.topology.Layer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  built\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Input shape tuple\n",
      " |          (or list of input shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output tensor or list of output tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape tuple(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one inbound node,\n",
      " |      or if all inbound nodes have the same output shape.\n",
      " |      \n",
      " |      # Returns\n",
      " |          Output shape tuple\n",
      " |          (or list of input shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      # Raises\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  weights\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/activations.py:115: UserWarning: Do not pass a layer instance (such as PRELU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n",
      "/Users/bjackson/research/Exoplanet-Artificial-Intelligence/model_fit_history.py:152: UserWarning: Update your `AveragePooling1D` call to the Keras 2 API: `AveragePooling1D(pool_size=3)`\n",
      "  model.add(AveragePooling1D(pool_length=pool_length))\n"
     ]
    }
   ],
   "source": [
    "model = mfh.make_cnn(Xc_train.shape[1])\n",
    "help(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = lambda x : np.array( list(x),dtype=np.float )\n",
    "data = pickle.load(open('pickle_data/transit_data_train.pkl','rb'))\n",
    "pvals = arr(data['results'][:,0])\n",
    "transits = arr(data['results'][:,1])\n",
    "null = arr(data['results'][:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.41421356e-02  2.00000000e+00  8.60000000e+01  1.50000000e+00\n",
      "  0.00000000e+00  2.50000000e-04  2.50000000e-01 -1.00000000e+00\n",
      " -3.00000000e+00]\n",
      "(155520, 180)\n"
     ]
    }
   ],
   "source": [
    "print(pvals[0,:])\n",
    "print(null.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
